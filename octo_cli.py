import cv2
import time
import os
import queue
import threading
import datetime
from motion_detection import detect_motion, draw_motion_visualization
from camera_utils import (
    initialize_cameras, release_cameras, create_video_grid,
    get_no_signal_frame, get_waiting_frame,
    MultiMaskCreator, load_mask, overlay_mask,load_lbph_face_recognizer
)
from view_logs import view_logs
from script_save import sv
from camera_utils import detect_and_recognize_faces, detect_faces_only
from logger import motion_logger
from loguru import logger
from config import CAMERA_INDICES, SYSTEM


print(r"""________  ____________________________        /\ __________.___                   
\_____  \ \_   ___ \__    ___/\_____  \      / / \______   \   |    ______ ___.__.
 /   |   \/    \  \/ |    |    /   |   \    / /   |     ___/   |    \____ <   |  |
/    |    \     \____|    |   /    |    \  / /    |    |   |   |    |  |_> >___  |
\_______  /\______  /|____|   \_______  / / /     |____|   |___| /\ |   __// ____|
        \/        \/                  \/  \/                     \/ |__|   \/     """)


class SurveillanceSystem:
    def __init__(self):
        self.camera_indices = CAMERA_INDICES.copy()  # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –û–°
        self.caps = []
        self.recognizer = None
        self.label_dict = None
        self.face_cascade = None
        self.masks = {}  # {camera_idx: mask}

        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –∫–∞–º–µ—Ä
        self.motion_detected = {idx: False for idx in self.camera_indices}
        self.prev_frames = {idx: None for idx in self.camera_indices}
        self.last_motion_time = {idx: 0 for idx in self.camera_indices}
        self.last_motion_check = {idx: 0 for idx in self.camera_indices}
        self.motion_start_time = {idx: 0 for idx in self.camera_indices}
        self.motion_contours = {idx: [] for idx in self.camera_indices}
        self.last_check_time = {idx: 0 for idx in self.camera_indices}

        self.camera_triggered = []
        self.camera_faces = []
        self.camera_motion = []
        # --- –ù–û–í–û–ï ---
        self.camera_recording = [] # –ö–∞–º–µ—Ä—ã, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –≤–∫–ª—é—á–µ–Ω–∞ –∑–∞–ø–∏—Å—å –ø–æ —Å–æ–±—ã—Ç–∏—é
        # --- /–ù–û–í–û–ï ---
        self.MOTION_TIMEOUT = 10
        self.MOTION_TIMEOUTS = {idx: 10 for idx in self.camera_indices}
        self.CHECK_INTERVAL = 1
        self.MOTION_THRESHOLD = 25  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        self.MOTION_THRESHOLDS = {idx: 25 for idx in self.camera_indices}  # –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞–º–µ—Ä—ã
        self.MOTION_MIN_AREA = 500

        self.active_motion_cameras = set()

        self.mask_creator = MultiMaskCreator()

        # --- –ù–û–í–û–ï (–¥–ª—è –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ) ---
        self.video_writers = {}
        self.recording_start_time = {}
        self.frame_queues = {}
        self.recording_threads = {}
        self.VIDEO_DURATION = 5  # —Å–µ–∫—É–Ω–¥
        self.FPS = 20
        self.VIDEO_DIR = "recordings"
        os.makedirs(self.VIDEO_DIR, exist_ok=True)
        # --- /–ù–û–í–û–ï ---

    def main_menu(self):
        logger.info("The main menu is opendos SurveillanceSystem")
        while True:
            print("\nMain Menu")
            print("1. Start Surveillance System")
            print("2. View Logs")
            print("3. Create Biometric Mask")
            print("4. Configure Masks")
            print("5. View Event Videos")  
            print("q. Exit")

            choice = input("  ")

            if choice == "1":
                self.run()  # –∑–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã
            elif choice == "2":
                view_logs()  # –ø—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤
            elif choice == "3":
                sv()
            elif choice == "4":
                self.setup_masks()
            elif choice == "5":  # üëà –ù–û–í–´–ô –ü–£–ù–ö–¢
                self.view_event_videos()
            elif choice == "q":
                logger.info("Shutting down...")
                logger.info("Exiting SurveillanceSystem")
                break
            else:
                logger.warning("Invalid choice")

    def view_event_videos(self):
        """–ü—Ä–æ—Å–º–æ—Ç—Ä –≤–∏–¥–µ–æ —Å–æ–±—ã—Ç–∏–π –∏–∑ –ø–∞–ø–∫–∏ recordings"""
        if not os.path.exists(self.VIDEO_DIR):
            logger.warning("No recordings folder found")
            logger.warning("No recordings found")
            input("Press Enter to continue")
            return

        print("\nEvent Videos")
        video_files = []
        file_paths = []

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ .avi —Ñ–∞–π–ª—ã
        for root, dirs, files in os.walk(self.VIDEO_DIR):
            for file in files:
                if file.lower().endswith('.avi'):
                    full_path = os.path.join(root, file)
                    relative_path = os.path.relpath(full_path, self.VIDEO_DIR)
                    video_files.append(relative_path)
                    file_paths.append(full_path)

        if not video_files:
            logger.warning("No video files found")
            input("Press Enter to continue")
            return

        while True:
            print(f"\nFound {len(video_files)} video(s):")
            for i, vid in enumerate(video_files, 1):
                print(f"{i}. {vid}")

            print("\nEnter number to play video, or 'q' to exit:")
            choice = input("  ").strip()

            if choice == 'q':
                break

            try:
                idx = int(choice) - 1
                if idx < 0 or idx >= len(file_paths):
                    logger.error("Invalid selection")
                    continue

                video_path = file_paths[idx]
                print(f"Playing: {video_path}")

                cap = cv2.VideoCapture(video_path)
                if not cap.isOpened():
                    logger.error("Cannot open video file")
                    continue

                cv2.namedWindow("Event Video Playback", cv2.WINDOW_NORMAL)
                while True:
                    ret, frame = cap.read()
                    if not ret:
                        print("End of video.")
                        break

                    cv2.imshow("Event Video Playback", frame)
                    key = cv2.waitKey(30) & 0xFF
                    if key == ord('q'):
                        break

                cap.release()
                cv2.destroyAllWindows()

            except ValueError:
                print("Please enter a number or 'q'.")
            except Exception as e:
                logger.error(f"Error playing video: {e}")

        print("Exited video viewer")
        
    def initialize(self, skip_settings=False):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã"""
        motion_logger.log_system_event("Initializing surveillance system")
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ª–∏—Ü
        try:
            self.recognizer, self.label_dict, self.face_cascade = load_lbph_face_recognizer(
                model_path="face_model.yml", 
                labels_path="labels.npy"
            )
            motion_logger.log_system_event("LBPH Face Recognizer loaded")
        except Exception as e:
            motion_logger.log_system_event(f"Error loading LBPH model: {e}")
            self.recognizer = None
            self.label_dict = None
            self.face_cascade = None


        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä
        self.caps = initialize_cameras(self.camera_indices)

        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–∞—Å–æ–∫
        self.load_all_masks()

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ skip_settings=True)
        if not skip_settings:
            self.get_user_settings()
        else:
            # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
            settings = {
                'cameras_faces': self.camera_faces,
                'cameras_motion': self.camera_motion,
                'cameras_recording': self.camera_recording,
                'cameras_triggered': self.camera_triggered,
                'timeouts': self.MOTION_TIMEOUTS,
                'threshold': self.MOTION_THRESHOLD,
                'min_area': self.MOTION_MIN_AREA,
                'masks': list(self.masks.keys())
            }
            motion_logger.log_settings(settings)

        motion_logger.log_system_event("System initialized")

    def load_all_masks(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–∞—Å–æ–∫ –∏–∑ –ø–∞–ø–∫–∏ masks"""
        masks_dir = "masks"
        if not os.path.exists(masks_dir):
            os.makedirs(masks_dir)
            return

        for filename in os.listdir(masks_dir):
            if filename.startswith("camera_") and filename.endswith(".png"):
                try:
                    parts = filename.split('_')
                    camera_idx = int(parts[1])
                    mask_path = os.path.join(masks_dir, filename)
                    mask = load_mask(mask_path)
                    if mask is not None:
                        self.masks[camera_idx] = mask
                        motion_logger.log_system_event(f"Loaded mask for camera {camera_idx}")
                except (ValueError, IndexError):
                    continue

    def get_user_settings(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        logger.info("Configuring system")
        print("=" * 50)

        print("Enter camera numbers for face detection:")
        print("Available cameras:", self.camera_indices)
        try:
            self.camera_faces = list(map(int, input("  ").split()))
        except Exception:
            self.camera_faces = []

        print("\nEnter camera numbers for motion detection:")
        print("Available cameras:", self.camera_indices)
        try:
            self.camera_motion = list(map(int, input("  ").split()))
        except Exception:
            self.camera_motion = []
        
        # --- –ù–û–í–û–ï ---
        print("\nEnter camera numbers for event recording (on motion):")
        print("Available cameras:", self.camera_indices)
        try:
            self.camera_recording = list(map(int, input("  ").split()))
        except Exception:
            self.camera_recording = []
        # --- /–ù–û–í–û–ï ---

        print("\nEnter camera numbers that activate only on motion:")
        print("Available cameras:", self.camera_indices)
        try:
            self.camera_triggered = list(map(int, input("  ").split()))
        except Exception:
            self.camera_triggered = []

        print("\nEnter timeouts (seconds) for each camera individually.")
        print("Format: press Enter to keep default (10s).")
        for cam_idx in self.camera_indices:
            try:
                v = input(f"  Cam{cam_idx} timeout (s) [current {self.MOTION_TIMEOUTS.get(cam_idx, 10)}]: ").strip()
                if v == "":
                    # –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    continue
                t = int(v)
                if t < 0:
                    logger.warning("Cannot set negative timeout")
                    continue
                self.MOTION_TIMEOUTS[cam_idx] = t
            except Exception:
                logger.warning("Invalid input")

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–∞—Å–æ–∫

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫
        settings = {
            'cameras_faces': self.camera_faces,
            'cameras_motion': self.camera_motion,
            # --- –ù–û–í–û–ï ---
            'cameras_recording': self.camera_recording,
            # --- /–ù–û–í–û–ï ---
            'cameras_triggered': self.camera_triggered,
            'timeouts': self.MOTION_TIMEOUTS,   # <-- changed
            'threshold': self.MOTION_THRESHOLD,
            'min_area': self.MOTION_MIN_AREA,
            'masks': list(self.masks.keys())
        }
        motion_logger.log_settings(settings)

    # --- –ù–û–í–û–ï (–º–µ—Ç–æ–¥—ã –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ) ---
    def start_recording(self, camera_idx, initial_frame, event_name="motion_detected"):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∑–∞–ø–∏—Å—å –≤–∏–¥–µ–æ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–∞–º–µ—Ä—ã."""
        if camera_idx not in self.camera_recording:
            return # –ö–∞–º–µ—Ä–∞ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏ –ø–æ —Å–æ–±—ã—Ç–∏—é

        # –ï—Å–ª–∏ –∑–∞–ø–∏—Å—å —É–∂–µ –∏–¥—ë—Ç, –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ–º –Ω–æ–≤—É—é
        if camera_idx in self.video_writers:
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞, —á—Ç–æ–±—ã –ø—Ä–æ–¥–ª–∏—Ç—å –∑–∞–ø–∏—Å—å
            self.recording_start_time[camera_idx] = time.time()
            return

        now = datetime.datetime.now()
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç—å: VIDEO_DIR / –¥–∞—Ç–∞ / —Å–æ–±—ã—Ç–∏–µ / –∫–∞–º–µ—Ä–∞
        date_dir = os.path.join(self.VIDEO_DIR, now.strftime("%Y-%m-%d"))
        event_dir = os.path.join(date_dir, event_name)
        camera_dir = os.path.join(event_dir, f"cam{camera_idx}")
        
        os.makedirs(camera_dir, exist_ok=True) # –°–æ–∑–¥–∞–µ–º –≤—Å—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
        
        filename = f"recording_{now.strftime('%H-%M-%S')}.avi"
        filepath = os.path.join(camera_dir, filename)

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ VideoWriter
        fourcc = cv2.VideoWriter_fourcc(*'XVID')
        writer = cv2.VideoWriter(filepath, fourcc, self.FPS, (initial_frame.shape[1], initial_frame.shape[0]))
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—á–µ—Ä–µ–¥–∏ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –∫–∞–¥—Ä–∞
        frame_queue = queue.Queue()
        frame_queue.put(initial_frame)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤
        self.video_writers[camera_idx] = writer
        self.recording_start_time[camera_idx] = time.time()
        self.frame_queues[camera_idx] = frame_queue

        # –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞ –∑–∞–ø–∏—Å–∏
        recording_thread = threading.Thread(target=self._write_video_thread, args=(camera_idx,))
        recording_thread.daemon = True
        recording_thread.start()
        self.recording_threads[camera_idx] = recording_thread

        motion_logger.log_system_event(f"Started recording for camera {camera_idx} on event '{event_name}' -> {filepath}")


    def stop_recording(self, camera_idx):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–∞–ø–∏—Å—å –≤–∏–¥–µ–æ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–∞–º–µ—Ä—ã."""
        if camera_idx in self.video_writers:
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ—Ç–æ–∫–∞
            self.frame_queues[camera_idx].put(None)
            
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–∞
            if camera_idx in self.recording_threads:
                self.recording_threads[camera_idx].join()
                del self.recording_threads[camera_idx]

            # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º VideoWriter
            self.video_writers[camera_idx].release()
            del self.video_writers[camera_idx]
            del self.recording_start_time[camera_idx]
            del self.frame_queues[camera_idx]

            motion_logger.log_system_event(f"Recording for camera {camera_idx} stopped")


    def _write_video_thread(self, camera_idx):
        """–ü–æ—Ç–æ–∫ –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ –∏–∑ –æ—á–µ—Ä–µ–¥–∏."""
        writer = self.video_writers[camera_idx]
        frame_queue = self.frame_queues[camera_idx]
        start_time = self.recording_start_time[camera_idx]
        
        while True:
            try:
                frame = frame_queue.get(timeout=1)
                if frame is None: # –°–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
                    break
                writer.write(frame)
            except queue.Empty:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ—Ä–∞ –ª–∏ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –∑–∞–ø–∏—Å—å
                elapsed = time.time() - start_time
                if elapsed >= self.VIDEO_DURATION:
                    break
                continue

        # –ó–∞–ø–∏—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∞
        writer.release()
        motion_logger.log_system_event(f"Video file for camera {camera_idx} closed")
    # --- /–ù–û–í–û–ï ---

    def process_triggered_camera(self, camera_idx, frame, current_time):
        mask = self.masks.get(camera_idx)
        display_frame = frame.copy()

        if self.motion_detected[camera_idx]:
            # –ê–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
            if current_time - self.last_motion_check.get(camera_idx, 0) > 0.5:
                if self.prev_frames[camera_idx] is not None:
                    threshold = self.MOTION_THRESHOLDS.get(camera_idx, self.MOTION_THRESHOLD)
                    motion, contours = detect_motion(
                        self.prev_frames[camera_idx], frame,
                        threshold, self.MOTION_MIN_AREA, mask
                    )
                    if motion:
                        # --- –ù–û–í–û–ï ---
                        if camera_idx in self.camera_recording:
                            self.start_recording(camera_idx, frame, event_name="motion_detected")
                        # --- /–ù–û–í–û–ï ---
                        self.last_motion_time[camera_idx] = current_time
                        motion_logger.log_system_event(f"Cam{camera_idx}: Motion continues")
                self.last_motion_check[camera_idx] = current_time
                self.prev_frames[camera_idx] = frame.copy()

            time_since_last_motion = current_time - self.last_motion_time[camera_idx]
            timeout = self.MOTION_TIMEOUTS.get(camera_idx, self.MOTION_TIMEOUT)
            time_left = int(timeout - time_since_last_motion)
            if time_since_last_motion > timeout:
                if camera_idx in self.active_motion_cameras:
                    duration = current_time - self.motion_start_time[camera_idx]
                    motion_logger.log_motion_stopped(camera_idx, duration, 0)
                    self.active_motion_cameras.remove(camera_idx)
                self.motion_detected[camera_idx] = False
                self.last_check_time[camera_idx] = current_time
                motion_logger.log_camera_status(camera_idx, "Transition to standby")
                # --- –ù–û–í–û–ï ---
                if camera_idx in self.video_writers:
                    self.stop_recording(camera_idx)
                # --- /–ù–û–í–û–ï ---
                return get_waiting_frame(camera_idx)

            display_frame = draw_motion_visualization(frame, [], camera_idx, mask, time_left)

            # Face recognition / detection
            if camera_idx in self.camera_faces:
                if self.recognizer:
                    # –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ - —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ª–∏—Ü
                    display_frame, face_boxes = detect_and_recognize_faces(
                        self.recognizer, self.label_dict, self.face_cascade, display_frame
                    )
                else:
                    # –ú–æ–¥–µ–ª—å –ù–ï –æ–±—É—á–µ–Ω–∞ - —Ç–æ–ª—å–∫–æ –¥–µ—Ç–µ–∫—Ü–∏—è (–≤—Å–µ –ª–∏—Ü–∞ –∫—Ä–∞—Å–Ω—ã–µ)
                    display_frame, face_boxes = detect_faces_only(display_frame)
                
                if face_boxes:
                    cv2.putText(display_frame, f"Faces: {len(face_boxes)}", (15, 145),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

            # Timestamp
            timestamp = datetime.datetime.now().strftime("%H:%M:%S")
            cv2.putText(display_frame, timestamp, (10, display_frame.shape[0] - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

            return display_frame

        else:
            # –†–µ–∂–∏–º –æ–∂–∏–¥–∞–Ω–∏—è
            time_since_last_check = current_time - self.last_check_time[camera_idx]
            if time_since_last_check >= self.CHECK_INTERVAL:
                if self.prev_frames[camera_idx] is not None:
                    threshold = self.MOTION_THRESHOLDS.get(camera_idx, self.MOTION_THRESHOLD)
                    motion, _ = detect_motion(
                        self.prev_frames[camera_idx], frame,
                        threshold, self.MOTION_MIN_AREA, mask
                    )
                    if motion:
                        # --- –ù–û–í–û–ï ---
                        if camera_idx in self.camera_recording:
                            self.start_recording(camera_idx, frame, event_name="motion_detected")
                        # --- /–ù–û–í–û–ï ---
                        self.motion_detected[camera_idx] = True
                        self.last_motion_time[camera_idx] = current_time
                        self.motion_start_time[camera_idx] = current_time
                        self.last_motion_check[camera_idx] = current_time
                        motion_logger.log_motion_detected(camera_idx, is_triggered=True)
                        self.active_motion_cameras.add(camera_idx)
                        self.prev_frames[camera_idx] = frame.copy()
                        display_frame = draw_motion_visualization(frame, [], camera_idx, mask, self.MOTION_TIMEOUT)
                        timestamp = datetime.datetime.now().strftime("%H:%M:%S")
                        cv2.putText(display_frame, timestamp, (10, display_frame.shape[0] - 10),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
                        return display_frame
                self.last_check_time[camera_idx] = current_time
                self.prev_frames[camera_idx] = frame.copy()

            waiting_frame = get_waiting_frame(camera_idx)
            if mask is not None:
                waiting_frame = overlay_mask(waiting_frame, mask)

            # Timestamp –Ω–∞ –∫–∞–¥—Ä–µ –æ–∂–∏–¥–∞–Ω–∏—è
            timestamp = datetime.datetime.now().strftime("%H:%M:%S")
            cv2.putText(waiting_frame, timestamp, (10, waiting_frame.shape[0] - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

            return waiting_frame


    def process_motion_camera(self, camera_idx, frame, current_time):
        mask = self.masks.get(camera_idx)
        display_frame = frame.copy()
    
        if self.motion_detected[camera_idx]:
            threshold = self.MOTION_THRESHOLDS.get(camera_idx, self.MOTION_THRESHOLD)
            motion, contours = detect_motion(
                self.prev_frames[camera_idx], frame,
                threshold, self.MOTION_MIN_AREA, mask
            )
            if motion:
                # --- –ù–û–í–û–ï ---
                if camera_idx in self.camera_recording:
                    self.start_recording(camera_idx, frame, event_name="motion_detected")
                # --- /–ù–û–í–û–ï ---
                self.last_motion_time[camera_idx] = current_time
                self.motion_contours[camera_idx] = contours
                objects_info = motion_logger.track_objects(camera_idx, contours)
                if objects_info['new_objects']:
                    motion_logger.log_new_objects(camera_idx, objects_info)
                motion_logger.log_motion_summary(camera_idx, objects_info)
    
            time_since_last_motion = current_time - self.last_motion_time[camera_idx]
            timeout = self.MOTION_TIMEOUTS.get(camera_idx, self.MOTION_TIMEOUT)
            time_left = int(timeout - time_since_last_motion)
            if time_since_last_motion > timeout:
                if camera_idx in self.active_motion_cameras:
                    duration = current_time - self.motion_start_time[camera_idx]
                    total_objects = motion_logger.object_counter.get(camera_idx, 0)
                    motion_logger.log_motion_stopped(camera_idx, duration, total_objects)
                    self.active_motion_cameras.remove(camera_idx)
                self.motion_detected[camera_idx] = False
                self.motion_contours[camera_idx] = []
                self.last_check_time[camera_idx] = current_time
                motion_logger.log_camera_status(camera_idx, "Transition to standby")
                # --- –ù–û–í–û–ï ---
                if camera_idx in self.video_writers:
                    self.stop_recording(camera_idx)
                # --- /–ù–û–í–û–ï ---
                return get_waiting_frame(camera_idx)
    
            self.prev_frames[camera_idx] = frame.copy()
            display_frame = draw_motion_visualization(frame, self.motion_contours[camera_idx], camera_idx, mask, time_left)
    
            # Face recognition / detection
            if camera_idx in self.camera_faces:
                if self.recognizer:
                    display_frame, face_boxes = detect_and_recognize_faces(
                        self.recognizer, self.label_dict, self.face_cascade, display_frame
                    )
                else:
                    display_frame, face_boxes = detect_faces_only(display_frame)
                
                if face_boxes:
                    cv2.putText(display_frame, f"Faces: {len(face_boxes)}", (15, 145),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    
            # Timestamp
            timestamp = datetime.datetime.now().strftime("%H:%M:%S")
            cv2.putText(display_frame, timestamp, (10, display_frame.shape[0] - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
    
            return display_frame

        else:
            # –ö–∞–º–µ—Ä–∞ –∂–¥—ë—Ç –¥–≤–∏–∂–µ–Ω–∏—è
            time_since_last_check = current_time - self.last_check_time[camera_idx]
            if time_since_last_check >= self.CHECK_INTERVAL:
                if self.prev_frames[camera_idx] is not None:
                    threshold = self.MOTION_THRESHOLDS.get(camera_idx, self.MOTION_THRESHOLD)
                    motion, contours = detect_motion(
                        self.prev_frames[camera_idx], frame,
                        threshold, self.MOTION_MIN_AREA, mask
                    )
                    if motion:
                        # --- –ù–û–í–û–ï ---
                        if camera_idx in self.camera_recording:
                            self.start_recording(camera_idx, frame, event_name="motion_detected")
                        # --- /–ù–û–í–û–ï ---
                        self.motion_detected[camera_idx] = True
                        self.last_motion_time[camera_idx] = current_time
                        self.motion_start_time[camera_idx] = current_time
                        self.motion_contours[camera_idx] = contours
                        objects_info = motion_logger.track_objects(camera_idx, contours)
                        if objects_info['new_objects']:
                            motion_logger.log_new_objects(camera_idx, objects_info)
                        motion_logger.log_motion_detected(camera_idx)
                        motion_logger.log_motion_summary(camera_idx, objects_info)
                        self.active_motion_cameras.add(camera_idx)
                        self.prev_frames[camera_idx] = frame.copy()
                        display_frame = draw_motion_visualization(frame, contours, camera_idx, mask, self.MOTION_TIMEOUT)
                        timestamp = datetime.datetime.now().strftime("%H:%M:%S")
                        cv2.putText(display_frame, timestamp, (10, display_frame.shape[0] - 10),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
                        return display_frame

                self.last_check_time[camera_idx] = current_time
                self.prev_frames[camera_idx] = frame.copy()

            waiting_frame = get_waiting_frame(camera_idx)
            if mask is not None:
                waiting_frame = overlay_mask(waiting_frame, mask)

            # Timestamp –Ω–∞ –∫–∞–¥—Ä–µ –æ–∂–∏–¥–∞–Ω–∏—è
            timestamp = datetime.datetime.now().strftime("%H:%M:%S")
            cv2.putText(waiting_frame, timestamp, (10, waiting_frame.shape[0] - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

            return waiting_frame


    def process_static_camera(self, camera_idx, frame):
        display_frame = frame.copy()
        mask = self.masks.get(camera_idx)
        if mask is not None:
            display_frame = overlay_mask(display_frame, mask)

        # Face recognition / detection
        if camera_idx in self.camera_faces:
            if self.recognizer is not None:
                display_frame, face_boxes = detect_and_recognize_faces(
                    self.recognizer, self.label_dict, self.face_cascade, display_frame
                )
            else:
                display_frame, face_boxes = detect_faces_only(display_frame)
            
            if face_boxes:
                cv2.putText(display_frame, f"Faces: {len(face_boxes)}",
                            (15, 145), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

        # –î–æ–±–∞–≤–ª—è–µ–º timestamp
        timestamp = datetime.datetime.now().strftime("%H:%M:%S")
        cv2.putText(display_frame, timestamp, 
                    (10, display_frame.shape[0] - 10), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

        return display_frame


    def process_camera_frame(self, camera_idx, frame, current_time):
        if frame is None:
            return get_no_signal_frame(camera_idx)

        frame = cv2.resize(frame, (640, 480))

        # --- –ù–û–í–û–ï ---
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –Ω–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å –¥–ª—è —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–∞–º–µ—Ä—ã —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –¥–≤–∏–∂–µ–Ω–∏—è
        if (camera_idx not in self.camera_triggered and 
            camera_idx not in self.camera_motion and 
            camera_idx in self.camera_recording and 
            camera_idx in self.camera_motion): # –ï—Å–ª–∏ –∫–∞–º–µ—Ä–∞ –Ω–µ –≤ TRIGGERED/MOTION, –Ω–æ –≤ recording –∏ motion
            # –î–ª—è —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–∞–º–µ—Ä—ã —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â–∏–π –∫–∞–¥—Ä –ø—Ä–æ—Ç–∏–≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ
            if self.prev_frames[camera_idx] is not None:
                mask = self.masks.get(camera_idx)
                threshold = self.MOTION_THRESHOLDS.get(camera_idx, self.MOTION_THRESHOLD)
                motion, _ = detect_motion(
                    self.prev_frames[camera_idx], frame,
                    threshold, self.MOTION_MIN_AREA, mask
                )
                if motion:
                    self.start_recording(camera_idx, frame, event_name="motion_detected")
            self.prev_frames[camera_idx] = frame.copy()
        # --- /–ù–û–í–û–ï ---

        # ‚úÖ –ö–∞–º–µ—Ä–∞ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –≤ —Ä–µ–∂–∏–º–∞—Ö TRIGGERED –∏ MOTION
        if camera_idx in self.camera_triggered and camera_idx in self.camera_motion:
            if self.motion_detected[camera_idx]:
                # –ö–∞–º–µ—Ä–∞ —É–∂–µ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞ ‚Üí —Ä–∞–±–æ—Ç–∞–µ–º –∫–∞–∫ motion-–∫–∞–º–µ—Ä–∞
                return self.process_motion_camera(camera_idx, frame, current_time)
            else:
                # –ö–∞–º–µ—Ä–∞ –∂–¥—ë—Ç –¥–≤–∏–∂–µ–Ω–∏—è ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ triggered
                return self.process_triggered_camera(camera_idx, frame, current_time)

        # –¢–æ–ª—å–∫–æ TRIGGERED
        elif camera_idx in self.camera_triggered:
            return self.process_triggered_camera(camera_idx, frame, current_time)

        # –¢–æ–ª—å–∫–æ MOTION
        elif camera_idx in self.camera_motion:
            return self.process_motion_camera(camera_idx, frame, current_time)

        # –°—Ç–∞—Ç–∏—á–µ—Å–∫–∞—è (–æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º)
        else:
            return self.process_static_camera(camera_idx, frame)


    def setup_masks(self):
        """–ü–æ–¥–º–µ–Ω—é –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∞—Å–æ–∫"""
        while True:
            print("Configure Masks")
            print("1. View Existing Masks")
            print("2. Create New Masks")
            print("3. Delete Masks")
            print("q. Back to Main Menu")

            choice = input("  ")

            if choice == "1":
                self.view_masks()
            elif choice == "2":
                self.create_masks()
            elif choice == "3":
                self.delete_masks()
            elif choice == "q":
                break
            else:
                logger.warning("Invalid choice")

    def view_masks(self):
        """–ü—Ä–æ—Å–º–æ—Ç—Ä —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –º–∞—Å–æ–∫"""
        masks_dir = "masks"
        if not os.path.exists(masks_dir):
            logger.warning("Folder 'masks' not found")
            return

        mask_files = [f for f in os.listdir(masks_dir) if f.endswith(".png")]
        if not mask_files:
            logger.warning("No masks found")
            return

        while True:
            print("View Masks")
            print("Available masks:")
            for i, mask_file in enumerate(mask_files, 1):
                print(f"{i}. {mask_file}")
            print("q. Exit")
            choice = input(" ").strip()
            if choice == "q":
                print("Exiting mask viewer.")
                break
            try:
                idx = int(choice)
                if idx < 1 or idx > len(mask_files):
                    logger.warning("Invalid mask number")
                    continue

                mask_path = os.path.join(masks_dir, mask_files[idx - 1])
                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
                if mask is None:
                    logger.error("Failed to load mask")
                    continue

                cv2.imshow(f"View Mask: {mask_files[idx - 1]}", mask)
                print("Close window to continue viewing other masks.")
                cv2.waitKey(0)
                cv2.destroyAllWindows()

            except ValueError:
                print("Enter a valid number or 'q' to exit.")


    def create_masks(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Å–æ–∫"""
        for cam_idx in self.camera_indices:
            print(f"\nCreate mask for camera {cam_idx} (y/n):")
            if input("  ").lower() == 'y':
                print("Enter mask name (Enter = 'default'):")
                mask_name = input("  ").strip() or "default"
                mask_path = self.mask_creator.create_mask(cam_idx, mask_name)
                if mask_path:
                    mask = load_mask(mask_path)
                    if mask is not None:
                        self.masks[cam_idx] = mask
                        logger.success(f"Created mask for camera {cam_idx}")
    def delete_masks(self):
        """–£–¥–∞–ª–µ–Ω–∏–µ –º–∞—Å–æ–∫"""
        masks_dir = "masks"
        if not os.path.exists(masks_dir):
            logger.warning("Folder 'masks' not found")
            return

        mask_files = [f for f in os.listdir(masks_dir) if f.endswith(".png")]
        if not mask_files:
            logger.warning("No masks found")
            return

        print("Available masks:")
        for i, mask_file in enumerate(mask_files, 1):
            print(f"{i}. {mask_file}")

        print("\nEnter mask numbers to delete (e.g., '1 3 5'):")
        try:
            choice = input("  ").strip()
            if not choice:
                print("Nothing selected.")
                return

            indices = list(map(int, choice.split()))
            indices = [idx - 1 for idx in indices if 1 <= idx <= len(mask_files)]  # –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫ –∏–Ω–¥–µ–∫—Å–∞–º —Å–ø–∏—Å–∫–∞

            if not indices:
                print("Invalid mask numbers.")
                return

            # –£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∏ –º–∞—Å–æ–∫ –∏–∑ –ø–∞–º—è—Ç–∏
            deleted_masks = []
            for idx in sorted(indices, reverse=True):  # —É–¥–∞–ª—è–µ–º —Å –∫–æ–Ω—Ü–∞, —á—Ç–æ–±—ã –Ω–µ —Å–±–∏—Ç—å –∏–Ω–¥–µ–∫—Å—ã
                mask_file = mask_files[idx]
                mask_path = os.path.join(masks_dir, mask_file)

                try:
                    os.remove(mask_path)
                    deleted_masks.append(mask_file)

                    # –£–¥–∞–ª—è–µ–º –º–∞—Å–∫—É –∏–∑ –ø–∞–º—è—Ç–∏ —Å–∏—Å—Ç–µ–º—ã
                    try:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –∫–∞–º–µ—Ä—ã –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                        parts = mask_file.split('_')
                        if len(parts) >= 2:
                            camera_idx_str = parts[1]
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —á–∞—Å—Ç—å —á–∏—Å–ª–æ–º
                            if camera_idx_str.isdigit():
                                camera_idx = int(camera_idx_str)
                                if camera_idx in self.masks:
                                    del self.masks[camera_idx]
                                    logger.success(f"Mask for camera {camera_idx} removed from memory")
                    except Exception:
                        pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –∏–∑ –ø–∞–º—è—Ç–∏

                except Exception as e:
                    logger.error(f"Error deleting mask {mask_file}: {e}")

            if deleted_masks:
                print(f"Deleted masks: {', '.join(deleted_masks)}")
                logger.success(f"Deleted masks: {', '.join(deleted_masks)}")
            else:
                logger.warning("Failed to delete selected masks")
        except ValueError:
            print("Invalid format. Enter numbers separated by space.")
        except Exception as e:
            logger.error(f"Error deleting masks: {e}")
    @logger.catch
    def run(self):
        try:
            self.initialize()
            while True:
                frames = []
                current_time = time.time()
                for idx, cap in enumerate(self.caps):
                    camera_idx = self.camera_indices[idx]
                    if cap.isOpened():
                        ret, frame = cap.read()
                        if ret:
                            processed_frame = self.process_camera_frame(camera_idx, frame, current_time)
                        else:
                            processed_frame = get_no_signal_frame(camera_idx)
                            motion_logger.log_camera_status(camera_idx, "No signal")
                    else:
                        processed_frame = get_no_signal_frame(camera_idx)
                        logger.critical(f"Camera {camera_idx}: not found")
                    
                    # --- –ù–û–í–û–ï ---
                    # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–¥—Ä –≤ –æ—á–µ—Ä–µ–¥—å –∑–∞–ø–∏—Å–∏, –µ—Å–ª–∏ –∑–∞–ø–∏—Å—å –∞–∫—Ç–∏–≤–Ω–∞
                    if camera_idx in self.video_writers:
                        try:
                            # –ö–æ–ø–∏—Ä—É–µ–º –∫–∞–¥—Ä, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º –≤ –¥—Ä—É–≥–∏—Ö –ø–æ—Ç–æ–∫–∞—Ö
                            frame_copy = processed_frame.copy()
                            self.frame_queues[camera_idx].put_nowait(frame_copy)
                        except queue.Full:
                            # –ï—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –ø–æ–ª–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–∞–¥—Ä
                            pass
                    # --- /–ù–û–í–û–ï ---

                    frames.append(cv2.resize(processed_frame, (320, 240)))

                grid = create_video_grid(frames, (2, 2), (640, 480))
                self.add_status_info(grid, current_time)
                cv2.imshow("Multi-Camera Surveillance System", grid)

                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('r'):
                    self.reset_motion_cameras()
                elif key == ord('+'):
                    self.adjust_sensitivity(-5)
                elif key == ord('-'):
                    self.adjust_sensitivity(5)
                elif key == ord('m'):
                    self.setup_masks()
        finally:
            self.cleanup()

    def add_status_info(self, grid, current_time):
        status_lines = []
        for cam_idx in self.camera_indices:
            status_parts = []
            if cam_idx in self.camera_faces:
                status_parts.append("Face Detection")
            if cam_idx in self.camera_motion:
                status_parts.append("Motion Detection")
            # --- –ù–û–í–û–ï ---
            if cam_idx in self.camera_recording:
                status_parts.append("Record On Event")
            # --- /–ù–û–í–û–ï ---
            if cam_idx in self.camera_triggered:
                if self.motion_detected[cam_idx]:
                    timeout = self.MOTION_TIMEOUTS.get(cam_idx, self.MOTION_TIMEOUT)
                    time_left = int(timeout - (current_time - self.last_motion_time[cam_idx]))
                    status_parts.append(f"TRIGGERED ({time_left}s)")
                else:
                    next_check = int(self.CHECK_INTERVAL - (current_time - self.last_check_time[cam_idx]))
                    status_parts.append(f"STANDBY ({next_check}s)")
            elif cam_idx in self.camera_motion:
                if self.motion_detected[cam_idx]:
                    timeout = self.MOTION_TIMEOUTS.get(cam_idx, self.MOTION_TIMEOUT)
                    time_left = int(timeout - (current_time - self.last_motion_time[cam_idx]))
                    status_parts.append(f"ACTIVE ({time_left}s)")
                else:
                    next_check = int(self.CHECK_INTERVAL - (current_time - self.last_check_time[cam_idx]))
                    status_parts.append(f"STANDBY ({next_check}s)")
            else:
                status_parts.append("ALWAYS ON")

            if cam_idx in self.masks:
                status_parts.append("MASK")

            status = " + ".join(status_parts)
            status_lines.append(f"Cam{cam_idx}:{status}")

        cv2.putText(grid, " | ".join(status_lines), (10, 20),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        
        controls = "'r': reset | '+/-': sensitivity | 'm': masks | 'q': quit"
        cv2.putText(grid, controls, (10, grid.shape[0] - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)

    def reset_motion_cameras(self):
        """–°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è –∫–∞–º–µ—Ä —Å –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –¥–≤–∏–∂–µ–Ω–∏—è"""
        for cam_idx in list(set(self.camera_motion + self.camera_triggered)):
            if cam_idx in self.active_motion_cameras:
                duration = time.time() - self.motion_start_time[cam_idx]
                total_objects = motion_logger.object_counter.get(cam_idx, 0)
                motion_logger.log_motion_stopped(cam_idx, duration, total_objects)
                self.active_motion_cameras.discard(cam_idx)

            self.motion_detected[cam_idx] = False
            self.prev_frames[cam_idx] = None
            self.last_motion_time[cam_idx] = 0
            self.last_motion_check[cam_idx] = 0
            self.last_check_time[cam_idx] = time.time()
            self.motion_contours[cam_idx] = []

            if cam_idx in self.camera_motion:
                motion_logger.reset_camera_objects(cam_idx)

        motion_logger.log_system_event("All cameras reset to standby mode")

    def adjust_sensitivity(self, delta):
        """–ò–∑–º–µ–Ω–µ–Ω–∏–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏"""
        old_threshold = self.MOTION_THRESHOLD
        self.MOTION_THRESHOLD = max(5, min(100, self.MOTION_THRESHOLD + delta))
        if old_threshold != self.MOTION_THRESHOLD:
            sensitivity = "increased" if delta < 0 else "decreased"
            motion_logger.log_system_event(
                f"Sensitivity {sensitivity}: threshold={self.MOTION_THRESHOLD}"
            )

    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏"""
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞–º–µ—Ä
        for cam_idx in list(self.active_motion_cameras):
            duration = time.time() - self.motion_start_time[cam_idx]
            total_objects = motion_logger.object_counter.get(cam_idx, 0)
            motion_logger.log_motion_stopped(cam_idx, duration, total_objects)

        # --- –ù–û–í–û–ï ---
        # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        for cam_idx in list(self.video_writers.keys()):
            self.stop_recording(cam_idx)
        # --- /–ù–û–í–û–ï ---

        motion_logger.log_system_event("Surveillance system shutdown")

        # –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
        release_cameras(self.caps)
        cv2.destroyAllWindows()


if __name__ == "__main__":
    system = SurveillanceSystem()
    system.main_menu()
